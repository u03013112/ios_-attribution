{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "031e3d99-7fe3-4846-b0af-5210ec3fa55a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE data_science.default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "085a0887-c389-491a-b077-51b4a2fa11e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "å°è¯•ä»ç›®å‰æ•°æ®ä¸­è·å¾—å°½å¯èƒ½å¤šçš„ç‰¹å¾ï¼š\n",
    "1ã€24å°æ—¶å†…çš„ä»˜è´¹æ¬¡æ•°ã€ä»˜è´¹æ€»é‡‘é¢ï¼Œæœ€å¤§å•æ¬¡ä»˜è´¹é‡‘é¢\n",
    "2ã€48å°æ—¶å†…çš„ä»˜è´¹æ¬¡æ•°ã€ä»˜è´¹æ€»é‡‘é¢ï¼Œæœ€å¤§å•æ¬¡ä»˜è´¹é‡‘é¢\n",
    "3ã€72å°æ—¶å†…çš„ä»˜è´¹æ¬¡æ•°ã€ä»˜è´¹æ€»é‡‘é¢ï¼Œæœ€å¤§å•æ¬¡ä»˜è´¹é‡‘é¢\n",
    "ä»¥åŠæœ€ç»ˆçš„ç»“æœï¼š\n",
    "168å°æ—¶ä»˜è´¹é‡‘é¢\n",
    "\n",
    "åˆ›å»ºä¸€ä¸ªviewæ¥æ–¹ä¾¿åç»­å¿«é€Ÿè·å–æ•°æ®,lw_20250820_aos_gpir_uid_revenue_view3_by_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e3f4bfbd-ae1e-4854-bd02-fb89756d27c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW lw_20250820_aos_gpir_uid_revenue_view3_by_j AS\n",
    "select\n",
    "\tuid,\n",
    "\tinstall_day,\n",
    "\t-- country,\n",
    "\tcountry_group,\n",
    "\tCASE\n",
    "\t\tWHEN mediasource = 'applovin_int'\n",
    "\t\tAND UPPER(campaign_name) LIKE '%D7%' THEN 'applovin_int_d7'\n",
    "\t\tWHEN mediasource = 'applovin_int'\n",
    "\t\tAND UPPER(campaign_name) LIKE '%D28%' THEN 'applovin_int_d28'\n",
    "\t\tWHEN mediasource IN (\n",
    "\t\t\t'googleadwords_int',\n",
    "\t\t\t'Facebook Ads',\n",
    "\t\t\t'bytedanceglobal_int',\n",
    "\t\t\t'snapchat_int',\n",
    "\t\t\t'moloco_int'\n",
    "\t\t) THEN mediasource\n",
    "\t\tELSE 'other'\n",
    "\tEND as mediasource,\n",
    "\tcampaign_id,\n",
    "  -- campaign_name,\n",
    "\tpayment_count_24h,\n",
    "\trevenue_24h as revenue_24h,\n",
    "\tmax_payment_24h,\n",
    "\tpayment_count_48h,\n",
    "\trevenue_48h,\n",
    "\tmax_payment_48h,\n",
    "\tpayment_count_72h,\n",
    "\trevenue_72h as revenue_72h,\n",
    "\tmax_payment_72h,\n",
    "\trevenue_168h as revenue_d7\n",
    "from\n",
    "\t(\n",
    "\t\tselect\n",
    "\t\t\tt1.uid,\n",
    "\t\t\tt1.install_timestamp,\n",
    "\t\t\tdate_format(from_unixtime(t1.install_timestamp), 'yyyyMMdd') as install_day,\n",
    "\t\t\tt1.country,\n",
    "\t\t\tCOALESCE(cg.country_group, 'other') AS country_group,\n",
    "\t\t\tt1.mediasource,\n",
    "\t\t\tt1.campaign_id,\n",
    "      pub.campaign_name as campaign_name,\n",
    "\t\t\tcount(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 24 * 60 * 60 then t2.revenue_value_usd end) as payment_count_24h,\n",
    "\t\t\tsum(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 24 * 60 * 60 then t2.revenue_value_usd else 0 end) as revenue_24h,\n",
    "\t\t\tmax(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 24 * 60 * 60 then t2.revenue_value_usd else 0 end) as max_payment_24h,\n",
    "\t\t\tcount(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 48 * 60 * 60 then t2.revenue_value_usd end) as payment_count_48h,\n",
    "\t\t\tsum(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 48 * 60 * 60 then t2.revenue_value_usd else 0 end) as revenue_48h,\n",
    "\t\t\tmax(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 48 * 60 * 60 then t2.revenue_value_usd else 0 end) as max_payment_48h,\n",
    "\t\t\tcount(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 72 * 60 * 60 then t2.revenue_value_usd end) as payment_count_72h,\n",
    "\t\t\tsum(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 72 * 60 * 60 then t2.revenue_value_usd else 0 end) as revenue_72h,\n",
    "\t\t\tmax(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 72 * 60 * 60 then t2.revenue_value_usd else 0 end) as max_payment_72h,\n",
    "\t\t\tsum(case when (t2.event_time / 1000 - t1.install_timestamp) between 0 and 168 * 60 * 60 then t2.revenue_value_usd else 0 end) as revenue_168h\n",
    "\t\tfrom\n",
    "\t\t\tmarketing.attribution.dws_overseas_gpir_unique_uid t1\n",
    "\t\t\tleft join marketing.attribution.dwd_overseas_revenue_allproject t2 on t1.app = t2.app\n",
    "\t\t\tand t1.uid = t2.uid\n",
    "\t\t\tLEFT JOIN lw_country_group_table_by_j_20250703 cg ON t1.country = cg.country\n",
    "\t\t\tLEFT JOIN (\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tcampaign_id,\n",
    "\t\t\t\t\tMAX(campaign_name) AS campaign_name\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\tprodb.public.applovin_campaign_info_new\n",
    "\t\t\t\tGROUP BY\n",
    "\t\t\t\t\tcampaign_id\n",
    "\t\t\t) pub ON t1.campaign_id = pub.campaign_id\n",
    "\t\twhere\n",
    "\t\t\tt1.app = 502\n",
    "\t\t\tand t1.app_package = 'com.fun.lastwar.gp'\n",
    "\t\tgroup by\n",
    "\t\t\tt1.uid,\n",
    "\t\t\tt1.install_timestamp,\n",
    "\t\t\tt1.country,\n",
    "\t\t\tCOALESCE(cg.country_group, 'other'),\n",
    "\t\t\tt1.mediasource,\n",
    "\t\t\tt1.campaign_id,\n",
    "\t\t\tpub.campaign_name\n",
    "\t)\n",
    "-- where\n",
    "-- \trevenue_168h > 0\n",
    "-- order by\n",
    "-- \trevenue_168h desc\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfd90cc2-1573-4c63-8c47-1078defd78bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- è¿™éƒ¨åˆ†ä»£ç åœ¨serverlessä¸­è¿è¡Œï¼Œä»¥ä¾¿äºå¿«ä¸€ç‚¹ã€‚\n",
    "\n",
    "-- åˆ é™¤ç°æœ‰VIEW\n",
    "DROP VIEW IF EXISTS lw_20250827_traindata_for_3p7_gbt_by_j;\n",
    "\n",
    "-- åˆ›å»ºç‰©åŒ–è¡¨\n",
    "CREATE OR REPLACE TABLE lw_20250827_traindata_for_3p7_gbt_by_j\n",
    "USING DELTA  -- ä½¿ç”¨Deltaæ ¼å¼è·å¾—æ›´å¥½æ€§èƒ½\n",
    "PARTITIONED BY (country_group)  -- æŒ‰country_groupåˆ†åŒº\n",
    "AS\n",
    "select\n",
    "  count(uid) as users,\n",
    "  country_group,\n",
    "  payment_count_24h,\n",
    "  ROUND(revenue_24h) as revenue_24h,\n",
    "  ROUND(max_payment_24h) as max_payment_24h,\n",
    "  payment_count_48h,\n",
    "  ROUND(revenue_48h) as revenue_48h,\n",
    "  ROUND(max_payment_48h) as max_payment_48h,\n",
    "  payment_count_72h,\n",
    "  ROUND(revenue_72h) as revenue_72h,\n",
    "  ROUND(max_payment_72h) as max_payment_72h,\n",
    "  ROUND(revenue_d7) as revenue_d7\n",
    "from lw_20250820_aos_gpir_uid_revenue_view3_by_j\n",
    "where install_day between 20250101 and 20250615\n",
    "GROUP BY\n",
    "  country_group,\n",
    "  payment_count_24h,\n",
    "  ROUND(revenue_24h),\n",
    "  ROUND(max_payment_24h),\n",
    "  payment_count_48h,\n",
    "  ROUND(revenue_48h),\n",
    "  ROUND(max_payment_48h),\n",
    "  payment_count_72h,\n",
    "  ROUND(revenue_72h),\n",
    "  ROUND(max_payment_72h),\n",
    "  ROUND(revenue_d7);\n",
    "\n",
    "-- ä¼˜åŒ–è¡¨ç»Ÿè®¡ä¿¡æ¯\n",
    "ANALYZE TABLE lw_20250827_traindata_for_3p7_gbt_by_j COMPUTE STATISTICS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a5a522bf-7b87-4964-b57c-cd7d4ebfd0c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select \n",
    "  users,\n",
    "  country_group,\n",
    "  payment_count_24h,\n",
    "  revenue_24h,\n",
    "  max_payment_24h,\n",
    "  payment_count_48h,\n",
    "  revenue_48h,\n",
    "  max_payment_48h,\n",
    "  payment_count_72h,\n",
    "  revenue_72h,\n",
    "  max_payment_72h,\n",
    "  revenue_d7\n",
    "from lw_20250827_traindata_for_3p7_gbt_by_j\n",
    "limit 10\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66bee34f-b406-41d4-b305-47d1e91eab29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "æ•°æ®å‡†å¤‡å’Œæ¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400be96d-1d42-4949-b714-0a49ac397680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# é¦–å…ˆå‡†å¤‡æ•°æ®\n",
    "sql = '''\n",
    "select \n",
    "  users,\n",
    "  country_group,\n",
    "  payment_count_24h,\n",
    "  revenue_24h,\n",
    "  max_payment_24h,\n",
    "  payment_count_48h,\n",
    "  revenue_48h,\n",
    "  max_payment_48h,\n",
    "  payment_count_72h,\n",
    "  revenue_72h,\n",
    "  max_payment_72h,\n",
    "  revenue_d7\n",
    "from lw_20250827_traindata_for_3p7_gbt_by_j\n",
    "where revenue_d7 is not null  -- ç¡®ä¿ç›®æ ‡å˜é‡ä¸ä¸ºç©º\n",
    "'''\n",
    "\n",
    "df = spark.sql(sql)\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
    "print(\"=== æ•°æ®åŸºæœ¬ä¿¡æ¯ ===\")\n",
    "print(f\"æ€»è¡Œæ•°: {df.count()}\")\n",
    "print(f\"æ€»åˆ—æ•°: {len(df.columns)}\")\n",
    "\n",
    "# æŸ¥çœ‹å„country_groupçš„æ•°æ®åˆ†å¸ƒ\n",
    "print(\"\\n=== Country Group åˆ†å¸ƒ ===\")\n",
    "from pyspark.sql.functions import count, avg, stddev\n",
    "\n",
    "country_stats = df.groupBy(\"country_group\").agg(\n",
    "    count(\"*\").alias(\"sample_count\"),\n",
    "    avg(\"revenue_d7\").alias(\"avg_revenue_d7\"),\n",
    "    stddev(\"revenue_d7\").alias(\"std_revenue_d7\")\n",
    ").orderBy(\"sample_count\", ascending=False)\n",
    "\n",
    "display(country_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1732a7b3-ca57-4d1b-810f-5a0dc4144247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "æ•°æ®è´¨é‡æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a7744d-6294-4261-be2f-300fe030badd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç©ºå€¼å’Œå¼‚å¸¸å€¼\n",
    "print(\"=== æ•°æ®è´¨é‡æ£€æŸ¥ ===\")\n",
    "\n",
    "# æ£€æŸ¥ç©ºå€¼\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull\n",
    "\n",
    "null_counts = df.select([\n",
    "    count(when(col(c).isNull() | isnan(col(c)), c)).alias(c) \n",
    "    for c in df.columns\n",
    "])\n",
    "print(\"ç©ºå€¼ç»Ÿè®¡:\")\n",
    "display(null_counts)\n",
    "\n",
    "# æ£€æŸ¥åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\nåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "display(df.describe())\n",
    "\n",
    "# æ£€æŸ¥æ¯ä¸ªcountry_groupçš„æ ·æœ¬æ•°é‡ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®­ç»ƒï¼‰\n",
    "min_samples_required = 100  # è®¾å®šæœ€å°æ ·æœ¬æ•°\n",
    "valid_countries = df.groupBy(\"country_group\").count().filter(col(\"count\") >= min_samples_required)\n",
    "print(f\"\\næ ·æœ¬æ•° >= {min_samples_required} çš„country_group:\")\n",
    "display(valid_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cfedf02-c365-404a-8eef-abdf40bc2d9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "å®šä¹‰è®­ç»ƒå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12059d41-e3d5-48c4-a96c-1af0b0126688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "import time\n",
    "\n",
    "def train_gbt_model_for_country(country_data, country_name):\n",
    "    \"\"\"\n",
    "    ä¸ºå•ä¸ªcountry_groupè®­ç»ƒGBTæ¨¡å‹\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"å¼€å§‹è®­ç»ƒ Country Group: {country_name}\")\n",
    "    print(f\"æ ·æœ¬æ•°é‡: {country_data.count()}\")\n",
    "    \n",
    "    # å®šä¹‰ç‰¹å¾åˆ—\n",
    "    feature_cols = [\n",
    "        'payment_count_24h', 'revenue_24h', 'max_payment_24h',\n",
    "        'payment_count_48h', 'revenue_48h', 'max_payment_48h', \n",
    "        'payment_count_72h', 'revenue_72h', 'max_payment_72h'\n",
    "    ]\n",
    "    \n",
    "    # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨\n",
    "    missing_cols = [col for col in feature_cols if col not in country_data.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"è­¦å‘Š: ç¼ºå°‘ç‰¹å¾åˆ— {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    # æ•°æ®åˆ†å‰²\n",
    "    train_data, test_data = country_data.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    print(f\"è®­ç»ƒé›†æ ·æœ¬æ•°: {train_data.count()}\")\n",
    "    print(f\"æµ‹è¯•é›†æ ·æœ¬æ•°: {test_data.count()}\")\n",
    "    \n",
    "    # åˆ›å»ºç‰¹å¾å‘é‡\n",
    "    vectorAssembler = VectorAssembler(\n",
    "        inputCols=feature_cols, \n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºGBTå›å½’å™¨ï¼Œä½¿ç”¨usersä½œä¸ºæƒé‡\n",
    "    gbt = GBTRegressor(\n",
    "        labelCol=\"revenue_d7\",\n",
    "        featuresCol=\"features\",\n",
    "        weightCol=\"users\",  # ä½¿ç”¨usersä½œä¸ºæƒé‡\n",
    "        maxIter=20,\n",
    "        maxDepth=5,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºç®¡é“\n",
    "    pipeline = Pipeline(stages=[vectorAssembler, gbt])\n",
    "    \n",
    "    # è®­ç»ƒæ¨¡å‹\n",
    "    start_time = time.time()\n",
    "    model = pipeline.fit(train_data)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f} ç§’\")\n",
    "    \n",
    "    # é¢„æµ‹å’Œè¯„ä¼°\n",
    "    predictions = model.transform(test_data)\n",
    "    \n",
    "    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
    "    evaluator_rmse = RegressionEvaluator(\n",
    "        labelCol=\"revenue_d7\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    evaluator_mae = RegressionEvaluator(\n",
    "        labelCol=\"revenue_d7\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"mae\"\n",
    "    )\n",
    "    \n",
    "    evaluator_r2 = RegressionEvaluator(\n",
    "        labelCol=\"revenue_d7\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"r2\"\n",
    "    )\n",
    "    \n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "    \n",
    "    print(f\"æ¨¡å‹è¯„ä¼°ç»“æœ:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    # è¿”å›ç»“æœ\n",
    "    return {\n",
    "        'country_group': country_name,\n",
    "        'model': model,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time,\n",
    "        'train_samples': train_data.count(),\n",
    "        'test_samples': test_data.count(),\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f17b82-8728-4ea8-9120-2f7e3106d610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "æ‰¹é‡è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1241be-71ad-4409-b6c1-e0eb34301f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# è·å–æ‰€æœ‰country_group\n",
    "countries = df.select(\"country_group\").distinct().rdd.map(lambda row: row[0]).collect()\n",
    "print(f\"éœ€è¦è®­ç»ƒçš„country_groupæ•°é‡: {len(countries)}\")\n",
    "print(f\"Country groups: {countries}\")\n",
    "\n",
    "# å­˜å‚¨æ‰€æœ‰æ¨¡å‹ç»“æœ\n",
    "model_results = {}\n",
    "training_summary = []\n",
    "\n",
    "# é€ä¸ªè®­ç»ƒæ¨¡å‹\n",
    "for i, country in enumerate(countries, 1):\n",
    "    print(f\"\\nè¿›åº¦: {i}/{len(countries)}\")\n",
    "    \n",
    "    try:\n",
    "        # è¿‡æ»¤å½“å‰countryçš„æ•°æ®\n",
    "        country_data = df.filter(col(\"country_group\") == country)\n",
    "        \n",
    "        # æ£€æŸ¥æ ·æœ¬æ•°é‡\n",
    "        sample_count = country_data.count()\n",
    "        if sample_count < 50:  # è®¾å®šæœ€å°æ ·æœ¬æ•°é˜ˆå€¼\n",
    "            print(f\"è·³è¿‡ {country}: æ ·æœ¬æ•°å¤ªå°‘ ({sample_count})\")\n",
    "            continue\n",
    "        \n",
    "        # è®­ç»ƒæ¨¡å‹\n",
    "        result = train_gbt_model_for_country(country_data, country)\n",
    "        \n",
    "        if result:\n",
    "            model_results[country] = result\n",
    "            training_summary.append({\n",
    "                'country_group': country,\n",
    "                'rmse': result['rmse'],\n",
    "                'mae': result['mae'],\n",
    "                'r2': result['r2'],\n",
    "                'training_time': result['training_time'],\n",
    "                'train_samples': result['train_samples'],\n",
    "                'test_samples': result['test_samples']\n",
    "            })\n",
    "            \n",
    "            print(f\"âœ… {country} è®­ç»ƒæˆåŠŸ\")\n",
    "        else:\n",
    "            print(f\"âŒ {country} è®­ç»ƒå¤±è´¥\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {country} è®­ç»ƒå‡ºé”™: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # æ¯è®­ç»ƒ5ä¸ªæ¨¡å‹åæ˜¾ç¤ºè¿›åº¦æ‘˜è¦\n",
    "    if i % 5 == 0:\n",
    "        print(f\"\\n--- è¿›åº¦æ‘˜è¦ (å·²å®Œæˆ {len(model_results)}/{i}) ---\")\n",
    "        if training_summary:\n",
    "            avg_rmse = sum([r['rmse'] for r in training_summary]) / len(training_summary)\n",
    "            avg_r2 = sum([r['r2'] for r in training_summary]) / len(training_summary)\n",
    "            print(f\"å¹³å‡ RMSE: {avg_rmse:.4f}\")\n",
    "            print(f\"å¹³å‡ RÂ²: {avg_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆ! æˆåŠŸè®­ç»ƒäº† {len(model_results)} ä¸ªæ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff3e1e84-18f2-4118-aebc-54188a383a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "è®­ç»ƒç»“æœæ±‡æ€»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb27314c-6ba8-48cf-8590-006a79d8a0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºè®­ç»ƒç»“æœæ±‡æ€»è¡¨\n",
    "if training_summary:\n",
    "    summary_df = spark.createDataFrame(training_summary)\n",
    "    \n",
    "    print(\"=== è®­ç»ƒç»“æœæ±‡æ€» ===\")\n",
    "    display(summary_df.orderBy(\"r2\", ascending=False))\n",
    "    \n",
    "    # è®¡ç®—æ•´ä½“ç»Ÿè®¡\n",
    "    print(\"\\n=== æ•´ä½“ç»Ÿè®¡ ===\")\n",
    "    summary_stats = summary_df.agg(\n",
    "        avg(\"rmse\").alias(\"avg_rmse\"),\n",
    "        avg(\"mae\").alias(\"avg_mae\"), \n",
    "        avg(\"r2\").alias(\"avg_r2\"),\n",
    "        avg(\"training_time\").alias(\"avg_training_time\")\n",
    "    )\n",
    "    display(summary_stats)\n",
    "    \n",
    "    # æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„æ¨¡å‹\n",
    "    best_model = summary_df.orderBy(\"r2\", ascending=False).first()\n",
    "    worst_model = summary_df.orderBy(\"r2\", ascending=True).first()\n",
    "    \n",
    "    print(f\"\\nè¡¨ç°æœ€å¥½çš„æ¨¡å‹: {best_model['country_group']} (RÂ² = {best_model['r2']:.4f})\")\n",
    "    print(f\"è¡¨ç°æœ€å·®çš„æ¨¡å‹: {worst_model['country_group']} (RÂ² = {worst_model['r2']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6095524550829790,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
