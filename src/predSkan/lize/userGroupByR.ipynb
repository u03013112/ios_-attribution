{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户用收入金额进行分组\n",
    "\n",
    "主要是针对R1和R7对用户进行分组   \n",
    "主要分为两个部分，一个部分进行区分，另一个部分进行校验   \n",
    "\n",
    "区分的部分目前大致思路有两个，一个按照总金额划分，一个按照人数划分   \n",
    "校验部分暂时选用之前的方式，用iOS整体数据进行验证"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jupyter-lab --allow-root --ip 192.168.40.62`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/src')\n",
    "from src.maxCompute import execSql\n",
    "from src.tools import getFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userDf 要求每个用户一行，必须包含install_date列\n",
    "# cvMapDf 要求必须包含 cv,min_event_revenue,max_event_revenue列\n",
    "# usd 是userDf中需要转化分组美元金额的列，一般是r1usd或者r7usd\n",
    "def checkCvMap(userDf,cvMapDf,usd = 'r1usd'):\n",
    "    import copy\n",
    "    df = copy.deepcopy(userDf)\n",
    "    df.loc[:,'cv'] = 0\n",
    "    for i in range(len(cvMapDf)):\n",
    "        min_event_revenue = cvMapDf.min_event_revenue[i]\n",
    "        max_event_revenue = cvMapDf.max_event_revenue[i]\n",
    "        if pd.isna(max_event_revenue):\n",
    "            continue\n",
    "        df.loc[\n",
    "            (df[usd] > min_event_revenue) & (df[usd] <= max_event_revenue),\n",
    "            'cv'\n",
    "        ] = i\n",
    "    df.loc[\n",
    "        (df[usd] > max_event_revenue),\n",
    "        'cv'\n",
    "    ] = len(cvMapDf)-1\n",
    "\n",
    "    df.loc[:,'cv_usd'] = 0\n",
    "    for i in range(len(cvMapDf)):\n",
    "        min_event_revenue = cvMapDf.min_event_revenue[i]\n",
    "        max_event_revenue = cvMapDf.max_event_revenue[i]\n",
    "        avg = (min_event_revenue + max_event_revenue)/2\n",
    "        if pd.isna(max_event_revenue):\n",
    "            avg = 0\n",
    "        if avg < 0:\n",
    "            avg = 0\n",
    "        df.loc[df.cv == i,'cv_usd'] = avg\n",
    "    \n",
    "    # print(df)\n",
    "    mergeDf = df.groupby('install_date',as_index=False).agg({usd:'sum','cv_usd':'sum'})\n",
    "    # print(mergeDf)\n",
    "    # 计算mergeDf中usd列与'cv_usd'列的mape 和 r2_score\n",
    "    from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "    mape = mean_absolute_percentage_error(mergeDf[usd], mergeDf['cv_usd'])\n",
    "    r2 = r2_score(mergeDf[usd], mergeDf['cv_usd'])\n",
    "\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels 没有0档位，类似 \n",
    "# levels = [\n",
    "#     2.4707,5.2468,18.9076,47.7314,94.9377,193.1167,234.78\n",
    "# ]\n",
    "def makeCvMap(levels):\n",
    "    mapData = {\n",
    "        'cv':[0],\n",
    "        'min_event_revenue':[-1],\n",
    "        'max_event_revenue':[0]\n",
    "    }\n",
    "    for i in range(len(levels)):\n",
    "        mapData['cv'].append(len(mapData['cv']))\n",
    "        mapData['min_event_revenue'].append(mapData['max_event_revenue'][len(mapData['max_event_revenue'])-1])\n",
    "        mapData['max_event_revenue'].append(levels[i])\n",
    "\n",
    "    cvMapDf = pd.DataFrame(data=mapData)\n",
    "    return cvMapDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这套方案的结论超越AF建议\n",
    "# 下面的注释直接放到Cursor中，获得下面代码，略有bug\n",
    "\n",
    "# userDf中列usd代表付费金额\n",
    "# 求数组levels，数组长度为N\n",
    "# 所有usd > 0 的用户按照levels范围进行分组，分成N组，即第一组用户usd >0 并且usd < levels[0],第二组用户 usd >= levels[0] 并且 usd < levels[1]，以此类推，大于levels[N-1]的用户也分到最后一组\n",
    "# 要求每组用户的usd的和尽量接近\n",
    "def makeLevels1(userDf,usd = 'r1usd',N = 7):\n",
    "    df = userDf.sort_values([usd])\n",
    "    # Filter out users with usd <= 0\n",
    "    filtered_df = df[df[usd] > 0]\n",
    "\n",
    "    # Calculate the total usd for all users\n",
    "    total_usd = filtered_df[usd].sum()\n",
    "\n",
    "    # Calculate the target usd for each group\n",
    "    target_usd = total_usd / N\n",
    "\n",
    "    # Initialize the levels array with zeros\n",
    "    levels = [0] * (N - 1)\n",
    "\n",
    "    # Initialize the current usd and group index\n",
    "    current_usd = 0\n",
    "    group_index = 0\n",
    "\n",
    "    # Loop through each user and assign them to a group\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        current_usd += row[usd]\n",
    "        if current_usd >= target_usd:\n",
    "            levels[group_index] = row[usd]\n",
    "            current_usd = 0\n",
    "            group_index += 1\n",
    "            if group_index == N - 1:\n",
    "                break\n",
    "\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeLevels1 test\n",
    "# df = pd.read_csv(getFilename('iosCvCount20220701_20230201'))\n",
    "# df = df.loc[df.install_date >= '2022-07-01']\n",
    "# df = df.sort_values(['install_date','r1usd'])\n",
    "# levels = makeLevels1(df)\n",
    "# print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    df = pd.read_csv(getFilename('iosCvCount20220701_20230201'))\n",
    "    df = df.loc[df.install_date >= '2022-07-01']\n",
    "    df = df.sort_values(['install_date','r1usd'])\n",
    "\n",
    "    cvMapDf = makeCvMap([2.4707,5.2468,18.9076,47.7314,94.9377,193.1167,234.78])\n",
    "    print(cvMapDf)\n",
    "\n",
    "    checkCvMap(df,cvMapDf,usd = 'r1usd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照cvMap添加cv到cvName列\n",
    "def addCV(df,cvMapDf,usd='r1usd',cvName = 'cv'):\n",
    "    df.loc[:,cvName] = 0\n",
    "    for i in range(len(cvMapDf)):\n",
    "        min_event_revenue = cvMapDf.min_event_revenue[i]\n",
    "        max_event_revenue = cvMapDf.max_event_revenue[i]\n",
    "        if pd.isna(max_event_revenue):\n",
    "            continue\n",
    "        df.loc[\n",
    "            (df[usd] > min_event_revenue) & (df[usd] <= max_event_revenue),\n",
    "            cvName\n",
    "        ] = i\n",
    "    df.loc[\n",
    "        (df[usd] > max_event_revenue),\n",
    "        cvName\n",
    "    ] = len(cvMapDf)-1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromMC():\n",
    "    sql = '''\n",
    "        select\n",
    "            customer_user_id,\n",
    "            to_char(\n",
    "                to_date(install_time, \"yyyy-mm-dd hh:mi:ss\"),\n",
    "                \"yyyy-mm-dd\"\n",
    "            ) as install_date,\n",
    "            sum(\n",
    "                case\n",
    "                    when event_timestamp - install_timestamp <= 1 * 24 * 3600 then cast (event_revenue_usd as double)\n",
    "                    else 0\n",
    "                end\n",
    "            ) as r1usd,\n",
    "            sum(\n",
    "                case\n",
    "                    when event_timestamp - install_timestamp <= 7 * 24 * 3600 then cast (event_revenue_usd as double)\n",
    "                    else 0\n",
    "                end\n",
    "            ) as r7usd\n",
    "        from\n",
    "            ods_platform_appsflyer_events\n",
    "        where\n",
    "            app_id = 'com.topwar.gp'\n",
    "            and event_name = 'af_purchase'\n",
    "            and zone = 0\n",
    "            and day >= 20220701\n",
    "            and day <= 20230201\n",
    "        group by\n",
    "            install_date,\n",
    "            customer_user_id\n",
    "    '''\n",
    "\n",
    "    df = execSql(sql)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取原始数据，需要跑mc，比较慢，可以跳过\n",
    "def step1():\n",
    "    df = getDataFromMC()\n",
    "    df.to_csv(getFilename('aosCvR1R7_20220701_20230201'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将用户打入标签cv1和cv2，代表r1和r7的用户分组\n",
    "def step2():\n",
    "    df = pd.read_csv(getFilename('aosCvR1R7_20220701_20230201'))\n",
    "    df = df.loc[df.install_date >= '2022-07-01']\n",
    "    df = df.sort_values(['install_date','r1usd'])\n",
    "\n",
    "    levels1 = makeLevels1(df,usd = 'r1usd',N=8)\n",
    "    levels7 = makeLevels1(df,usd = 'r7usd',N=8)\n",
    "\n",
    "    cvMapDf1 = makeCvMap(levels1)\n",
    "    cvMapDf7 = makeCvMap(levels7)\n",
    "\n",
    "    cvMapDf1.to_csv(getFilename('cvMap1'))\n",
    "    cvMapDf7.to_csv(getFilename('cvMap7'))\n",
    "\n",
    "    # 测试map的准确性\n",
    "    checkCvMap(df,cvMapDf1,usd = 'r1usd')\n",
    "    checkCvMap(df,cvMapDf7,usd = 'r7usd')\n",
    "\n",
    "    df = addCV(df,cvMapDf1,usd = 'r1usd',cvName = 'cv1')\n",
    "    df = addCV(df,cvMapDf7,usd = 'r7usd',cvName = 'cv7')\n",
    "    \n",
    "    # df.to_csv(getFilename('iosCvCount20220701_20230201_cv1cv7'))\n",
    "    df.to_csv(getFilename('aosCvCount20220701_20230201_cv1cv7'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照cv1和cv7进行分组，然后计算相关度\n",
    "def step3():\n",
    "    # df = pd.read_csv(getFilename('iosCvCount20220701_20230201_cv1cv7'))\n",
    "    df = pd.read_csv(getFilename('aosCvCount20220701_20230201_cv1cv7'))\n",
    "    # 计算原有相关度\n",
    "    groupByDayDf = df.groupby(by = ['install_date'],as_index=False).agg({'r1usd':'sum','r7usd':'sum'})\n",
    "    groupByDayCorr = groupByDayDf.corr()\n",
    "    print('groupByDayCorr:',groupByDayCorr)\n",
    "\n",
    "    groupByDayDf = df.groupby(by = ['install_date','cv1'],as_index=False).agg({'r1usd':'sum','r7usd':'sum'})\n",
    "    for cv1 in list(groupByDayDf['cv1'].unique()):\n",
    "        groupByDayDf1 = groupByDayDf.loc[groupByDayDf.cv1 == cv1]\n",
    "        groupByDayCorr = groupByDayDf1.corr() \n",
    "        print('groupByDayCorr cv1:',cv1,'\\n',groupByDayCorr)\n",
    "\n",
    "    # 分组\n",
    "    for cv1 in range(8):\n",
    "        for cv7 in range(8):\n",
    "            cvDf = df.loc[(df.cv1 == cv1) & (df.cv7 == cv7)].reset_index(drop = True)\n",
    "            if(len(cvDf) > 0):\n",
    "                print('groupByCV %d %d:\\n'%(cv1,cv7))\n",
    "                # print(cvDf)\n",
    "                print('共计%d人:'%(len(cvDf)))\n",
    "\n",
    "                groupByCVDf = cvDf.groupby(by = ['install_date','cv1','cv7'],as_index=False).agg({'r1usd':'sum','r7usd':'sum'})                \n",
    "                print('Corr:\\n',groupByCVDf.corr())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 暂时总结\n",
    "观察后发现，大体上还是可以得到一些较大的群组。   \n",
    "但是存在一些较小的群组，比如 0 7组人数就很少。   \n",
    "人数多的群组相关性足够高，超过95%，人数少的相关性偏低，甚至出现负相关。   \n",
    "目前只分了64组，如果可以考虑忽略掉一部分小概率人群，可能可以让相关性上升。   \n",
    "一旦涉及到cv7 == 7 的情况，就会出现负相关，所以考虑对大R进行削弱，`设定大R上限`。   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新思路 速记\n",
    "\n",
    "鉴于将用户有效的分为64组（或更少），可以分开对用户进行预测。\n",
    "即根据首日付费金额 + 预测结果 -> CV\n",
    "\n",
    "这种思路主要问题：\n",
    "cv1分组和cv7分组的合理性，更加有效的将用户划分为64组。   \n",
    "可能不能均分，并不能直接cv1 x cv7，需要将增长率相似的用户合并成一组，腾出更多的空间使那些增长率不稳定的或者大R更多的选择。\n",
    "\n",
    "这个可能暂时没有什么思路怎么动手，但是可以先将cv1和cv7的档位放大，做出更多的可能档位，然后尝试进行合并。   \n",
    "可以合并线性相关度较高的相邻cv7组别，合并后线性相关性会下降，观察下降后的相关度是否足以继续合并（比如定个阈值90%）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试对cv7进行合并\n",
    "# def catCv7(df,t = 0.9):\n",
    "# df中有列'install_date','cv1,'cv7','r1usd,'r7usd'\n",
    "# 并尝试尽量合并相邻的cv7并记作cv7m\n",
    "# 要求合并后按install_date,cv1 和 cv7m进行groupby之后的'r1usd,'r7usd'的相关系数corr > t\n",
    "\n",
    "def catCv7(t = 0.9):\n",
    "    df = pd.read_csv(getFilename('iosCvCount20220701_20230201_cv1cv7'))\n",
    "\n",
    "    cv1List = list(df['cv1'].unique())\n",
    "    cv7List = list(df['cv7'].unique())\n",
    "    cv1List.sort()\n",
    "    cv7List.sort()\n",
    "    \n",
    "    for cv1 in cv1List:\n",
    "        # 要尝试合并cv7 ，并把可以合并的cv7 标记为 cv7m\n",
    "        if cv1 == 0:\n",
    "            continue\n",
    "        cv7Group = []            \n",
    "        for cv7 in cv7List:\n",
    "            cv7Group.append(cv7)\n",
    "            cvDf = df.loc[(df.cv1 == cv1) & (df.cv7.isin(cv7Group))].reset_index(drop = True)\n",
    "            if(len(cvDf) > 0):\n",
    "                groupByCVDf = cvDf.groupby(by = ['install_date'],as_index=False).agg({'r1usd':'sum','r7usd':'sum'})\n",
    "                corr = groupByCVDf.corr()['r1usd']['r7usd']\n",
    "                print(cv7Group,corr)\n",
    "                if corr < t or cv7 == cv7List[len(cv7List)-1]:\n",
    "                    print('!')\n",
    "                    if len(cv7Group) > 1:\n",
    "                        cv7Group.pop()\n",
    "                    cvDf = df.loc[(df.cv1 == cv1) & (df.cv7.isin(cv7Group))].reset_index(drop = True)\n",
    "                    groupByCVDf = cvDf.groupby(by = ['install_date'],as_index=False).agg({'r1usd':'sum','r7usd':'sum'})\n",
    "                    corr = groupByCVDf.corr()['r1usd']['r7usd']\n",
    "                    print('cv1:',cv1,'cv7Group:',cv7Group,'corr:',corr)\n",
    "                    cv7Group = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCv7()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ddbb1e7c0f5392e763e7ed0105eea523a83d8be62b40910beaeae08f4eab658"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
