{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9866954a-8592-4d92-88e6-ca3a0ae93945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "按照app_package,country_group,mediasource分组，计算平均N天的均值，并添加tag：avg_{N}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84b706d0-53cd-4f0e-948f-ebd57bbdd6ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createAvgNView(N=21):\n",
    "    viewName = f\"data_science.default.lw_20250903_cohort_onlyprofit_avg_{N}_view_by_j\"\n",
    "    sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW {viewName} as\n",
    "with base_data as (\n",
    "    select\n",
    "        app_package,\n",
    "        country_group,\n",
    "        mediasource,\n",
    "        tag,\n",
    "        install_day,\n",
    "        cost,\n",
    "        revenue_d1,\n",
    "        revenue_d3,\n",
    "        revenue_d7,\n",
    "        revenue_d14,\n",
    "        revenue_d30,\n",
    "        revenue_d60,\n",
    "        revenue_d90,\n",
    "        revenue_d120,\n",
    "        revenue_d135,\n",
    "        revenue_d150,\n",
    "        -- 计算每个分组内有多少天的数据\n",
    "        count(*) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as days_count\n",
    "    from\n",
    "        (\n",
    "\t\t\tselect * from data_science.default.lw_20250903_aos_gpir_cohort_onlyprofit_raw_table_by_j\n",
    "\t\t\tunion all\n",
    "\t\t\tselect * from data_science.default.lw_20250903_ios_af_cohort_onlyprofit_fit_table_by_j\n",
    "        )\n",
    "        \n",
    "),\n",
    "averaged_data as (\n",
    "    select\n",
    "        app_package,\n",
    "        country_group,\n",
    "        mediasource,\n",
    "        tag,\n",
    "        install_day,\n",
    "        -- 只有当有足够N天数据时才计算平均值，否则为NULL\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(cost) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_cost,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d1) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d1,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d3) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d3,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d7) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d7,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d14) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d14,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d30) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d30,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d60) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d60,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d90) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d90,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d120) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d120,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d135) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d135,\n",
    "        case \n",
    "            when days_count >= {N} then \n",
    "                avg(revenue_d150) over (\n",
    "                    partition by app_package, country_group, mediasource, tag\n",
    "                    order by install_day \n",
    "                    rows between {N-1} preceding and current row\n",
    "                )\n",
    "            else null \n",
    "        end as avg_revenue_d150\n",
    "    from\n",
    "        base_data\n",
    ")\n",
    "select\n",
    "    app_package,\n",
    "    country_group,\n",
    "    mediasource,\n",
    "    'avg_{N}' as tag,\n",
    "    install_day,\n",
    "    avg_cost as cost,\n",
    "    avg_revenue_d1 as revenue_d1,\n",
    "    avg_revenue_d3 as revenue_d3,\n",
    "    avg_revenue_d7 as revenue_d7,\n",
    "    avg_revenue_d14 as revenue_d14,\n",
    "    avg_revenue_d30 as revenue_d30,\n",
    "    avg_revenue_d60 as revenue_d60,\n",
    "    avg_revenue_d90 as revenue_d90,\n",
    "    avg_revenue_d120 as revenue_d120,\n",
    "    avg_revenue_d135 as revenue_d135,\n",
    "    avg_revenue_d150 as revenue_d150\n",
    "from\n",
    "    averaged_data;\n",
    "    \"\"\"\n",
    "    print(f\"Executing SQL: {sql}\")\n",
    "    spark.sql(sql)\n",
    "    return viewName\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49982623-08bd-41a0-9e80-2ef3423cf412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "按照app_package,country_group,mediasource分组，计算平均N天的移动均值，并添加tag：ema_{N}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6cfd0d1-da1a-4fbd-864f-ed790bff621e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createEMAView(N=21):\n",
    "    alpha = 2.0 / (N + 1)  # 平滑因子\n",
    "    one_minus_alpha = 1 - alpha\n",
    "    viewName = f\"data_science.default.lw_20250903_cohort_onlyprofit_ema_{N}_view_by_j\"\n",
    "    sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW {viewName} as\n",
    "with base_data as (\n",
    "    select\n",
    "        app_package,\n",
    "        country_group,\n",
    "        mediasource,\n",
    "        tag,\n",
    "        install_day,\n",
    "        cost,\n",
    "        revenue_d1,\n",
    "        revenue_d3,\n",
    "        revenue_d7,\n",
    "        revenue_d14,\n",
    "        revenue_d30,\n",
    "        revenue_d60,\n",
    "        revenue_d90,\n",
    "        revenue_d120,\n",
    "        revenue_d135,\n",
    "        revenue_d150,\n",
    "        row_number() over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day\n",
    "        ) as rn\n",
    "    from\n",
    "        (\n",
    "\t\t\tselect * from data_science.default.lw_20250903_aos_gpir_cohort_onlyprofit_raw_table_by_j\n",
    "\t\t\tunion all\n",
    "\t\t\tselect * from data_science.default.lw_20250903_ios_af_cohort_onlyprofit_fit_table_by_j\n",
    "        )\n",
    "),\n",
    "windowed_data as (\n",
    "    select \n",
    "        *,\n",
    "        -- 为窗口内每行计算相对位置（0到N-1）\n",
    "        collect_list(cost) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as cost_window,\n",
    "        collect_list(revenue_d1) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d1_window,\n",
    "        collect_list(revenue_d3) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d3_window,\n",
    "        collect_list(revenue_d7) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d7_window,\n",
    "        collect_list(revenue_d14) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d14_window,\n",
    "        collect_list(revenue_d30) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d30_window,\n",
    "        collect_list(revenue_d60) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d60_window,\n",
    "        collect_list(revenue_d90) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d90_window,\n",
    "        collect_list(revenue_d120) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d120_window,\n",
    "        collect_list(revenue_d135) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d135_window,\n",
    "        collect_list(revenue_d150) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        ) as revenue_d150_window,\n",
    "        size(collect_list(cost) over (\n",
    "            partition by app_package, country_group, mediasource, tag\n",
    "            order by install_day \n",
    "            rows between {N-1} preceding and current row\n",
    "        )) as window_size\n",
    "    from base_data\n",
    ")\n",
    "select\n",
    "    app_package,\n",
    "    country_group,\n",
    "    mediasource,\n",
    "    'ema_{N}' as tag,\n",
    "    install_day,\n",
    "    -- 只有当窗口大小达到N时才计算EMA\n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + cost_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as cost,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d1_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d1,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d3_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d3,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d7_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d7,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d14_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d14,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d30_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d30,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d60_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d60,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d90_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d90,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d120_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d120,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d135_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d135,\n",
    "    \n",
    "    case when window_size >= {N} then\n",
    "        aggregate(\n",
    "            sequence(0, {N-1}),\n",
    "            cast(0.0 as double),\n",
    "            (acc, i) -> acc + revenue_d150_window[i] * {alpha} * power({one_minus_alpha}, {N-1} - i)\n",
    "        ) / (1 - power({one_minus_alpha}, {N}))\n",
    "    else null end as revenue_d150\n",
    "from\n",
    "    windowed_data;\n",
    "    \"\"\"\n",
    "    print(f\"Executing SQL for EMA with N={N}, alpha={alpha:.4f}\")\n",
    "    spark.sql(sql)\n",
    "    return viewName\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011834ec-c664-46dc-881e-d7f1df14c81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "将view都合并到一起，以便后续处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "69261e21-2e08-47b9-bba1-078c776d2242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createOnlyprofitAllFuncView(viewNames=None):\n",
    "    \"\"\"\n",
    "    创建汇总视图，动态读取视图名称列表\n",
    "    \n",
    "    Args:\n",
    "        viewNames: 视图名称列表，如果为None则使用默认配置\n",
    "    \"\"\"\n",
    "    if viewNames is None:\n",
    "        # 默认配置\n",
    "        viewNames = [\n",
    "            'lw_20250903_aos_gpir_cohort_onlyprofit_avg_28_view_by_j',\n",
    "        ]\n",
    "    \n",
    "    # 动态构建UNION ALL语句\n",
    "    union_statements = []\n",
    "    for view_name in viewNames:\n",
    "        union_statements.append(f\"SELECT\\n*\\nFROM {view_name}\")\n",
    "    \n",
    "    union_sql = \"\\nUNION ALL\\n\".join(union_statements)\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW data_science.default.lw_20250903_onlyprofit_all_func_view_by_j as\n",
    "{union_sql}\n",
    ";\n",
    "    \"\"\"\n",
    "    print(f\"Executing SQL: {sql}\")\n",
    "    spark.sql(sql)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6b1f00f-2869-4f5b-8901-8602e635f7b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 创建各种视图\n",
    "avg_views = []\n",
    "ema_views = []\n",
    "\n",
    "for n in [28, 56, 84]:\n",
    "    view_name = createAvgNView(n)\n",
    "    avg_views.append(view_name)\n",
    "    view_name = createEMAView(n)\n",
    "    ema_views.append(view_name)\n",
    "\n",
    "# 合并所有视图名称\n",
    "all_view_names = avg_views + ema_views\n",
    "\n",
    "# 动态创建汇总视图\n",
    "createOnlyprofitAllFuncView(all_view_names)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8692605093799300,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "计算均值python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
